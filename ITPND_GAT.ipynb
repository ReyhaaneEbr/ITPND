{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "XxRZl6fRAm6I"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2OWZ6uHGcuD"
      },
      "source": [
        "#GAT_PB IID (Having Isolated Nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxRZl6fRAm6I"
      },
      "source": [
        "##Load Libaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qgRfm335GmPy",
        "outputId": "20ba789b-c1a5-488e-e670-dcd9a54f6481"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ogb\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.0.2)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (4.67.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.6.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.2.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.11/dist-packages (from ogb) (2.5.0)\n",
            "Collecting outdated>=0.2.0 (from ogb)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (75.2.0)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from outdated>=0.2.0->ogb) (2.32.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.0->ogb) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.20.0->ogb) (3.6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.6.0->ogb)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.6.0->ogb) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.6.0->ogb) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.6.0->ogb) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->outdated>=0.2.0->ogb) (2025.8.3)\n",
            "Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, littleutils, outdated, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ogb\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed littleutils-0.2.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 ogb-1.3.6 outdated-0.2.2\n",
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.12.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.8.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.11/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.14.1)\n",
            "Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install ogb\n",
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "ZJWcu4-8GmPy",
        "outputId": "69db4896-926b-4307-9982-190582788efa"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1862806994.py, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1862806994.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install torch\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "pip install torch\n",
        "from torch._C import *\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GATConv\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import precision_recall_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import numpy as np\n",
        "from scipy.sparse import coo_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hj9R3aEyAr2K"
      },
      "source": [
        "##GAT Model Layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMZKzLGKGmPz"
      },
      "outputs": [],
      "source": [
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels,num_classes,num_layers, dropout):\n",
        "        super(GAT, self).__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.fc = torch.nn.ModuleList()\n",
        "        self.convs.append(GATConv(in_channels, hidden_channels))\n",
        "        for _ in range(num_layers - 2):\n",
        "            self.convs.append(GATConv(hidden_channels, hidden_channels))\n",
        "        self.convs.append(GATConv(hidden_channels, out_channels))\n",
        "        self.fc.append(torch.nn.Linear(out_channels,num_classes))\n",
        "        self.dropout = dropout\n",
        "\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "\n",
        "    def forward(self, x, adj_t):\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, adj_t)\n",
        "            x = F.relu(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        for fc in self.fc[:-1]:\n",
        "            x = fc(x)\n",
        "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
        "        x = self.fc[-1](x)\n",
        "        return x\n",
        "\n",
        "def train(model, data, train_idx, optimizer):\n",
        "      model.train()\n",
        "      criterion = torch.nn.CrossEntropyLoss(weight=weights)\n",
        "      optimizer.zero_grad()\n",
        "      out = model(data.x, data.adj_t)[train_idx]\n",
        "      loss = criterion(out, data.y[train_idx])\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      return loss.item()\n",
        "\n",
        "def to_one_hot(y, num_classes):\n",
        "    y_one_hot = torch.zeros(y.size(0), num_classes).to(y.device)\n",
        "    y_one_hot.scatter_(1, y.view(-1, 1), 1)\n",
        "    return y_one_hot\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(model, data, split_idx, num_classes):\n",
        "    model.eval()\n",
        "\n",
        "    y_probs = model(data.x, data.adj_t)\n",
        "    y_probs = torch.softmax(y_probs, dim=1)\n",
        "\n",
        "    y_true_train = to_one_hot(data.y[split_idx['train']], num_classes)\n",
        "    y_true_valid = to_one_hot(data.y[split_idx['valid']], num_classes)\n",
        "    y_true_test = to_one_hot(data.y[split_idx['test']], num_classes)\n",
        "\n",
        "    def compute_metrics(y_true, y_probs):\n",
        "        y_pred_labels = y_probs.argmax(dim=1).cpu().numpy()\n",
        "        y_true_labels = y_true.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        acc = accuracy_score(y_true_labels, y_pred_labels)\n",
        "        prec = precision_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        rec = recall_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        f1 = f1_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        rocauc = roc_auc_score(y_true.cpu(), y_probs.cpu())\n",
        "        y_true_cpu = y_true.cpu()\n",
        "        y_true_binarized = label_binarize(y_true_cpu, classes=[0, 1])\n",
        "        y_probs_cpu = y_probs.cpu().numpy()\n",
        "        precision, recall, _ = precision_recall_curve(y_true_binarized[:, 1], [score[1] for score in y_probs_cpu])\n",
        "        auprc = auc(recall, precision)\n",
        "\n",
        "        return [acc, prec, rec, f1, rocauc, auprc]\n",
        "\n",
        "    train_metrics = compute_metrics(y_true_train, y_probs[split_idx['train']])\n",
        "    valid_metrics = compute_metrics(y_true_valid, y_probs[split_idx['valid']])\n",
        "    test_metrics = compute_metrics(y_true_test, y_probs[split_idx['test']])\n",
        "\n",
        "    return train_metrics, valid_metrics, test_metrics\n",
        "\n",
        "@torch.no_grad()\n",
        "def test_kfold(model, data, split_idx, num_classes):\n",
        "    model.eval()\n",
        "\n",
        "    y_probs = model(data.x, data.adj_t)\n",
        "    y_probs = torch.softmax(y_probs, dim=1)\n",
        "\n",
        "    y_true_train = to_one_hot(data.y[split_idx['train']], num_classes)\n",
        "    #y_true_valid = to_one_hot(data.y[split_idx['valid']], num_classes)\n",
        "    y_true_test = to_one_hot(data.y[split_idx['test']], num_classes)\n",
        "\n",
        "    def compute_metrics(y_true, y_probs):\n",
        "        y_pred_labels = y_probs.argmax(dim=1).cpu().numpy()\n",
        "        y_true_labels = y_true.argmax(dim=1).cpu().numpy()\n",
        "\n",
        "        acc = accuracy_score(y_true_labels, y_pred_labels)\n",
        "        prec = precision_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        rec = recall_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        f1 = f1_score(y_true_labels, y_pred_labels, zero_division=0)\n",
        "        rocauc = roc_auc_score(y_true.cpu(), y_probs.cpu())\n",
        "        y_true_cpu = y_true.cpu()\n",
        "        y_true_binarized = label_binarize(y_true_cpu, classes=[0, 1])\n",
        "        y_probs_cpu = y_probs.cpu().numpy()\n",
        "        precision, recall, _ = precision_recall_curve(y_true_binarized[:, 1], [score[1] for score in y_probs_cpu])\n",
        "        auprc = auc(recall, precision)\n",
        "\n",
        "        return [acc, prec, rec, f1, rocauc, auprc]\n",
        "\n",
        "    train_metrics = compute_metrics(y_true_train, y_probs[split_idx['train']])\n",
        "    test_metrics = compute_metrics(y_true_test, y_probs[split_idx['test']])\n",
        "\n",
        "    return train_metrics, test_metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RP7G_m6Aw7N"
      },
      "source": [
        "##Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNorN9KDBlBH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e83d672a-557f-4110-ae64-71d5dc9d4e8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdDDPUesGmPz"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_features = pd.read_csv('/content/gdrive/MyDrive/New_Repo_Data/embeddings_mean_protbert_3k.csv')\n",
        "df_features.iloc[:,1:-1] = np.random.uniform(low=-3, high=6, size=(5609, 1024))\n",
        "\n",
        "df_labels = df_features .iloc[:4819, [0, -1]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OAzHFjwGmPz",
        "outputId": "0078a7b1-314b-417d-b610-cab9235d3fcd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4819, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df_labels.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrgkBkPsTeur"
      },
      "outputs": [],
      "source": [
        "df_labels['Id'] = df_labels['Id'].astype(str)\n",
        "df_features['Id'] = df_features['Id'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApYlpYtQGmP0"
      },
      "outputs": [],
      "source": [
        "order_dict = {value: index for index, value in enumerate(list(df_labels['Id']))}\n",
        "\n",
        "def sorting_key(value):\n",
        "    return (order_dict.get(value, float('inf')), value)\n",
        "\n",
        "df_features = df_features.sort_values(by='Id', key=lambda x: x.map(sorting_key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6UkQIadGmP0",
        "outputId": "c5d96157-8299-41cf-e912-eb3da1c1d776"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5609, 1026)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "df_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "6rd6bPeLGmP0"
      },
      "outputs": [],
      "source": [
        "import networkx as nx\n",
        "\n",
        "graph_data = pd.read_csv('/content/gdrive/MyDrive/New_Repo_Data/new_ppi_edges_iid.csv')\n",
        "id_list = list(df_features['Id'])\n",
        "\n",
        "G = nx.Graph()\n",
        "for id1,id2 in zip(list(graph_data.iloc[:,0]),list(graph_data.iloc[:,1])):\n",
        "  if((str(id1) in id_list) and (str(id2) in id_list)):\n",
        "    G.add_edge(id1,id2)\n",
        "df_features = df_features[df_features['Id'].isin(list(G.nodes()))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuL8Jgx0GmP1"
      },
      "outputs": [],
      "source": [
        "adj_sparse = nx.adjacency_matrix(G, nodelist=list(df_features.iloc[:,0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m77rSCDpGmP1"
      },
      "outputs": [],
      "source": [
        "node_labels = np.array(df_features.iloc[:,-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4xaake9Tjdc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "adj_matrix = coo_matrix(adj_sparse).todense()\n",
        "# Define the number of nodes and features\n",
        "num_nodes = 4819\n",
        "num_features = 1024\n",
        "num_classes = 2\n",
        "\n",
        "node_features = np.array(df_features.iloc[:,1:-1])\n",
        "node_names = np.array(df_features.iloc[:,0])\n",
        "\n",
        "adj_matrix = (adj_matrix + adj_matrix.T) / 2\n",
        "adj_matrix[adj_matrix < 0.9] = 0  # Sparsify the adjacency matrix\n",
        "\n",
        "node_features_tensor = torch.from_numpy(node_features).float()\n",
        "node_labels_tensor = torch.from_numpy(node_labels).long()  # Convert labels to long type\n",
        "\n",
        "adj_coo = adj_sparse.tocoo()\n",
        "indices = np.vstack((adj_coo.row, adj_coo.col))\n",
        "values = adj_sparse.data\n",
        "\n",
        "indices_tensor = torch.tensor(indices, dtype=torch.long)\n",
        "values_tensor = torch.tensor(values, dtype=torch.float)\n",
        "\n",
        "adj_t = torch.sparse_coo_tensor(indices_tensor, values_tensor, adj_sparse.shape).to_sparse_csr()\n",
        "\n",
        "data = Data(uni_id=node_names ,x=node_features_tensor, adj_t=adj_t, y=node_labels_tensor)\n",
        "\n",
        "# Assuming your data structure\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Map unique IDs to indices\n",
        "id_to_idx_map = {id_: idx for idx, id_ in enumerate(data.uni_id)}\n",
        "\n",
        "# Function to load folds (train.npy and test.npy) from Google Drive\n",
        "def load_folds(folds_dir):\n",
        "    folds = []\n",
        "    for fold in range(1, 6):  # Assuming 5 folds (1 to 5)\n",
        "        # Define the paths for train.npy and test.npy for each fold\n",
        "        train_path = os.path.join(folds_dir, f'fold_{fold}_train_ids.csv')\n",
        "        test_path = os.path.join(folds_dir, f'fold_{fold}_test_ids.csv')\n",
        "\n",
        "        # Load the train and test files\n",
        "        train_ids = pd.read_csv(train_path)  # This should load the numpy array of IDs\n",
        "        test_ids = pd.read_csv(test_path)\n",
        "\n",
        "        # Map the IDs to indices\n",
        "        train_idx = torch.tensor([id_to_idx_map[id_] for id_ in list (train_ids.iloc[:,0])], dtype=torch.long).to(device)\n",
        "        test_idx = torch.tensor([id_to_idx_map[id_] for id_ in list (test_ids.iloc[:,0])], dtype=torch.long).to(device)\n",
        "\n",
        "        # Append the tuple of train and test indices for this fold\n",
        "        folds.append((train_idx, test_idx))\n",
        "\n",
        "    return folds\n",
        "\n",
        "folds_dir = \"/content/gdrive/MyDrive/New_Repo_Data/5folds\"  # Update this path to your Google Drive directory\n",
        "folds = load_folds(folds_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hu3uhp7LBG0D"
      },
      "source": [
        "##Run Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGAukhwOtjV5",
        "outputId": "5cdabf44-15c7-4101-cb71-6b3cc36566e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 1/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4179168249.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_idx = torch.tensor(train_idx, dtype=torch.long).to(device)\n",
            "/tmp/ipython-input-4179168249.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_idx = torch.tensor(test_idx, dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 2/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4179168249.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_idx = torch.tensor(train_idx, dtype=torch.long).to(device)\n",
            "/tmp/ipython-input-4179168249.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_idx = torch.tensor(test_idx, dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 3/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4179168249.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_idx = torch.tensor(train_idx, dtype=torch.long).to(device)\n",
            "/tmp/ipython-input-4179168249.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_idx = torch.tensor(test_idx, dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 4/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4179168249.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_idx = torch.tensor(train_idx, dtype=torch.long).to(device)\n",
            "/tmp/ipython-input-4179168249.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_idx = torch.tensor(test_idx, dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Fold 5/5 ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4179168249.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_idx = torch.tensor(train_idx, dtype=torch.long).to(device)\n",
            "/tmp/ipython-input-4179168249.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  test_idx = torch.tensor(test_idx, dtype=torch.long).to(device)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Final Report ===\n",
            "Metric          Mean     Std      Var      Min      Max     \n",
            "\n",
            "**Accuracy**\n",
            "Train:\t0.9256 ± 0.0098\t(var: 0.0001)\t[0.9102-0.9367]\n",
            "Test:\t0.7829 ± 0.0126\t(var: 0.0002)\t[0.7656-0.7985]\n",
            "\n",
            "**Precision**\n",
            "Train:\t0.9596 ± 0.0097\t(var: 0.0001)\t[0.9412-0.9696]\n",
            "Test:\t0.8560 ± 0.0078\t(var: 0.0001)\t[0.8470-0.8664]\n",
            "\n",
            "**Recall**\n",
            "Train:\t0.9226 ± 0.0176\t(var: 0.0003)\t[0.8953-0.9416]\n",
            "Test:\t0.7942 ± 0.0242\t(var: 0.0006)\t[0.7581-0.8169]\n",
            "\n",
            "**F1**\n",
            "Train:\t0.9406 ± 0.0083\t(var: 0.0001)\t[0.9273-0.9495]\n",
            "Test:\t0.8237 ± 0.0127\t(var: 0.0002)\t[0.8081-0.8383]\n",
            "\n",
            "**ROC AUC**\n",
            "Train:\t0.9819 ± 0.0031\t(var: 0.0000)\t[0.9782-0.9857]\n",
            "Test:\t0.8658 ± 0.0105\t(var: 0.0001)\t[0.8455-0.8754]\n",
            "\n",
            "**PR AUC**\n",
            "Train:\t0.9887 ± 0.0019\t(var: 0.0000)\t[0.9865-0.9913]\n",
            "Test:\t0.8998 ± 0.0099\t(var: 0.0001)\t[0.8801-0.9065]\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import KFold\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Hyper-parameters and settings\n",
        "hidden_channels = 128\n",
        "out_channels = 64\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "runs = 5\n",
        "lr = 0.001\n",
        "epochs = 500\n",
        "eval_steps = 10\n",
        "log_steps = 10\n",
        "weights = torch.tensor([2.0,1.0])\n",
        "num_classes = 2\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load data and folds\n",
        "data = data.to(device)\n",
        "weights = weights.to(device)\n",
        "model = GAT(in_channels=data.num_features,\n",
        "            hidden_channels=hidden_channels,\n",
        "            out_channels=out_channels,\n",
        "            num_classes=num_classes,\n",
        "            num_layers=num_layers,\n",
        "            dropout=dropout).to(device)\n",
        "\n",
        "# Metrics storage\n",
        "train_acc_list, train_prec_list, train_rec_list = [], [], []\n",
        "train_f1_list, train_rocauc_list, train_aucprc_list = [], [], []\n",
        "test_acc_list, test_prec_list, test_rec_list = [], [], []\n",
        "test_f1_list, test_rocauc_list, test_aucprc_list = [], [], []\n",
        "\n",
        "# Main training loop\n",
        "for fold, (train_idx, test_idx) in enumerate(folds):\n",
        "    print(f'\\n=== Fold {fold + 1}/{len(folds)} ===')\n",
        "    train_idx = torch.tensor(train_idx, dtype=torch.long).to(device)\n",
        "    test_idx = torch.tensor(test_idx, dtype=torch.long).to(device)\n",
        "    split_idx = {'train': train_idx, 'test': test_idx}\n",
        "\n",
        "    model.reset_parameters()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    best_train_rocauc = 0\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        loss = train(model, data, train_idx, optimizer)\n",
        "        loss_history.append(loss)\n",
        "\n",
        "        # Early stopping check\n",
        "        if len(loss_history) > 10 and np.std(loss_history[-10:]) < 1e-3:\n",
        "            print(f\"Early stopping at epoch {epoch}\")\n",
        "            break\n",
        "\n",
        "        # Evaluation\n",
        "        if epoch % eval_steps == 0 or epoch == epochs:\n",
        "            train_metrics, test_metrics = test_kfold(model, data, split_idx, num_classes)\n",
        "            train_rocauc = train_metrics[4]\n",
        "\n",
        "            # Save best model\n",
        "            if train_rocauc > best_train_rocauc:\n",
        "                best_train_rocauc = train_rocauc\n",
        "                torch.save(model.state_dict(), f'best_model_fold_{fold}.pt')\n",
        "\n",
        "    # Final evaluation with best model\n",
        "    model.load_state_dict(torch.load(f'best_model_fold_{fold}.pt'))\n",
        "    train_metrics, test_metrics = test_kfold(model, data, split_idx, num_classes)\n",
        "\n",
        "    # Store metrics\n",
        "    for lst, values in zip([train_acc_list, train_prec_list, train_rec_list, train_f1_list, train_rocauc_list, train_aucprc_list],\n",
        "                           train_metrics):\n",
        "        lst.append(values)\n",
        "\n",
        "    for lst, values in zip([test_acc_list, test_prec_list, test_rec_list, test_f1_list, test_rocauc_list, test_aucprc_list],\n",
        "                           test_metrics):\n",
        "        lst.append(values)\n",
        "\n",
        "# Metrics calculations\n",
        "def calculate_stats(metric_list, name):\n",
        "    return {\n",
        "        'mean': np.mean(metric_list),\n",
        "        'std': np.std(metric_list),\n",
        "        'var': np.var(metric_list),\n",
        "        'min': np.min(metric_list),\n",
        "        'max': np.max(metric_list)\n",
        "    }\n",
        "\n",
        "# Generate report\n",
        "print(\"\\n=== Final Report ===\")\n",
        "print(\"{:<15} {:<8} {:<8} {:<8} {:<8} {:<8}\".format(\n",
        "    'Metric', 'Mean', 'Std', 'Var', 'Min', 'Max'))\n",
        "\n",
        "for metric_name, train_list, test_list in [\n",
        "    ('Accuracy', train_acc_list, test_acc_list),\n",
        "    ('Precision', train_prec_list, test_prec_list),\n",
        "    ('Recall', train_rec_list, test_rec_list),\n",
        "    ('F1', train_f1_list, test_f1_list),\n",
        "    ('ROC AUC', train_rocauc_list, test_rocauc_list),\n",
        "    ('PR AUC', train_aucprc_list, test_aucprc_list)\n",
        "]:\n",
        "    train_stats = calculate_stats(train_list, 'Train')\n",
        "    test_stats = calculate_stats(test_list, 'Test')\n",
        "\n",
        "    print(f\"\\n**{metric_name}**\")\n",
        "    print(\"Train:\\t{mean:.4f} ± {std:.4f}\\t(var: {var:.4f})\\t[{min:.4f}-{max:.4f}]\".format(**train_stats))\n",
        "    print(\"Test:\\t{mean:.4f} ± {std:.4f}\\t(var: {var:.4f})\\t[{min:.4f}-{max:.4f}]\".format(**test_stats))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5nsPZqSsZkp"
      },
      "outputs": [],
      "source": []
    }
  ]
}